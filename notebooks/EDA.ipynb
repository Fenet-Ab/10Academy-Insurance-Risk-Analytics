{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02568c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/MachineLearningRating_v3.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/raw/MachineLearningRating_v3.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/MachineLearningRating_v3.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/MachineLearningRating_v3.txt\")\n",
    "\n",
    "df.head()\n",
    "# df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_missing</th>\n",
       "      <th>pct_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_missing  pct_missing\n",
       "age               0          0.0\n",
       "sex               0          0.0\n",
       "bmi               0          0.0\n",
       "children          0          0.0\n",
       "smoker            0          0.0\n",
       "region            0          0.0\n",
       "charges           0          0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent=(df.isnull().mean()*100).sort_values(ascending=False)\n",
    "pd.concat([missing,missing_percent],axis=1,keys=[\"n_missing\",\"pct_missing\"]).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0b8fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['PolicyID'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9002/3203325847.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PolicyID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6968\u001b[0m         \u001b[0;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6969\u001b[0m         \u001b[0;31m# key that doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6970\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6972\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6975\u001b[0m             \u001b[0;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['PolicyID'], dtype='object')"
     ]
    }
   ],
   "source": [
    "df.duplicated(subset=[\"PolicyID\"]).sum()\n",
    "cat_cols = [\"Province\",\"VehicleType\",\"Gender\",\"Make\",\"Model\",\"PostalCode\",\"CoverType\"]\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c95b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LossRatio\"] = df[\"TotalClaims\"] / df[\"TotalPremium\"]\n",
    "# Claim frequency: policy-level indicator (1 if any claim)\n",
    "df[\"HasClaim\"] = (df[\"TotalClaims\"] > 0).astype(int)\n",
    "# Claim severity conditional on claim\n",
    "df_claims = df[df[\"HasClaim\"]==1].copy()\n",
    "df_claims[\"ClaimSeverity\"] = df_claims[\"TotalClaims\"]  # rename for clarity\n",
    "# Margin\n",
    "df[\"Margin\"] = df[\"TotalPremium\"] - df[\"TotalClaims\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"TotalPremium\",\"TotalClaims\",\"CustomValueEstimate\",\"CalculatedPremiumPerTerm\",\"LossRatio\"]\n",
    "df[num_cols].describe().T\n",
    "\n",
    "# Additional variability metrics:\n",
    "df[num_cols].agg([\"mean\",\"median\",\"std\",\"var\",\"min\",\"max\",\"skew\",\"kurtosis\"]).T\n",
    "# Interquartile range\n",
    "iqr = df[num_cols].quantile(0.75) - df[num_cols].quantile(0.25)\n",
    "iqr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa94625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for col in [\"TotalClaims\",\"TotalPremium\",\"CustomValueEstimate\"]:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[col].dropna(), bins=60)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "    # Log plot if skewed (add 1 to handle zeros)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(np.log1p(df[col].dropna()), bins=60)\n",
    "    plt.title(f\"log1p({col})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x=df[\"TotalClaims\"])\n",
    "plt.title(\"TotalClaims boxplot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e57cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Province\",\"VehicleType\",\"Gender\"]:\n",
    "    grp = df.groupby(col)[\"LossRatio\"].agg([\"mean\",\"median\",\"count\",\"std\"]).sort_values(\"mean\", ascending=False)\n",
    "    display(grp.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=\"Province\", y=\"LossRatio\", data=df, estimator=np.mean)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Average LossRatio by Province\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be71441",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df.groupby(\"Province\")[\"HasClaim\"].mean().sort_values(ascending=False)\n",
    "sev = df_claims.groupby(\"Province\")[\"ClaimSeverity\"].mean().sort_values(ascending=False)\n",
    "pd.concat([freq, sev], axis=1, keys=[\"ClaimFreq\",\"AvgSeverity\"]).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df.set_index(\"TransactionMonth\").resample(\"M\").agg({\n",
    "    \"TotalClaims\":\"sum\",\n",
    "    \"TotalPremium\":\"sum\",\n",
    "    \"HasClaim\":\"mean\"   # frequency as proportion per month\n",
    "})\n",
    "ts[\"LossRatio\"] = ts[\"TotalClaims\"] / ts[\"TotalPremium\"]\n",
    "ts.plot(subplots=True, figsize=(10,8), title=\"Monthly trends\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pct = ts.pct_change().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = df.groupby(\"PostalCode\").agg({\n",
    "    \"TotalPremium\":\"sum\",\n",
    "    \"TotalClaims\":\"sum\",\n",
    "    \"HasClaim\":\"mean\"\n",
    "}).reset_index()\n",
    "pc[\"LossRatio\"] = pc[\"TotalClaims\"]/pc[\"TotalPremium\"]\n",
    "\n",
    "# Scatter: premium vs claims\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=pc.sample(500), x=\"TotalPremium\", y=\"TotalClaims\", size=\"HasClaim\", alpha=0.6)\n",
    "plt.xscale(\"log\"); plt.yscale(\"log\")\n",
    "plt.title(\"PostalCode: TotalPremium vs TotalClaims (sample)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = df.groupby([\"Make\",\"Model\"]).agg({\n",
    "    \"TotalClaims\":\"mean\",\n",
    "    \"HasClaim\":\"mean\",\n",
    "    \"TotalPremium\":\"mean\",\n",
    "    \"LossRatio\":\"mean\",\n",
    "    \"PolicyID\":\"count\"\n",
    "}).rename(columns={\"PolicyID\":\"n_policies\"}).sort_values(\"TotalClaims\", ascending=False)\n",
    "mm.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51655530",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_filtered = mm[mm[\"n_policies\"] >= 30]  # threshold\n",
    "mm_filtered.sort_values(\"LossRatio\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df[[\"TotalPremium\",\"TotalClaims\",\"CustomValueEstimate\",\"LossRatio\"]].copy()\n",
    "corr = num.corr()\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
    "plt.title(\"Correlation matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outliers(series):\n",
    "    q1, q3 = series.quantile(0.25), series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    return series[(series < lower) | (series > upper)]\n",
    "\n",
    "outliers_claims = iqr_outliers(df[\"TotalClaims\"].dropna())\n",
    "len(outliers_claims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592160bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Faceted barplot (Province Ã— top VehicleTypes)\n",
    "top_types = df[\"VehicleType\"].value_counts().nlargest(6).index\n",
    "sub = df[df[\"VehicleType\"].isin(top_types)]\n",
    "g = sns.catplot(data=sub, x=\"Province\", y=\"LossRatio\", col=\"VehicleType\",\n",
    "                kind=\"bar\", col_wrap=3, height=3, aspect=1.6, sharey=True)\n",
    "g.set_xticklabels(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scatter with marginal histograms (seaborn jointplot won't handle size easily, so use scatter + hist)\n",
    "agg_pc = df.groupby(\"PostalCode\").agg({\n",
    "    \"TotalPremium\":\"sum\",\"TotalClaims\":\"sum\",\"PolicyID\":\"count\"\n",
    "}).rename(columns={\"PolicyID\":\"n_policies\"})\n",
    "agg_pc[\"LossRatio\"] = agg_pc[\"TotalClaims\"]/agg_pc[\"TotalPremium\"]\n",
    "samp = agg_pc.sample(1000).reset_index()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(samp[\"TotalPremium\"], samp[\"TotalClaims\"], \n",
    "            s=(samp[\"n_policies\"]/samp[\"n_policies\"].max())*200, # size\n",
    "            c=samp[\"LossRatio\"], alpha=0.6)\n",
    "plt.xscale(\"log\"); plt.yscale(\"log\")\n",
    "plt.colorbar(label=\"LossRatio\")\n",
    "plt.xlabel(\"TotalPremium (log)\")\n",
    "plt.ylabel(\"TotalClaims (log)\")\n",
    "plt.title(\"PostalCode aggregated premium vs claims (sample)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
